#!/usr/bin/env python3
"""
weight_gap_comparison_complete.py
å®Œæ•´ç‰ˆ - åŒ…å«S1->S3åˆ†æž
"""

import torch
import numpy as np
import matplotlib.pyplot as plt
import pickle
import os
import glob
import networkx as nx
from tqdm import tqdm
import json
from datetime import datetime

try:
    from model import GPTConfig, GPT
except ImportError:
    print("âŒ Error: Cannot import 'model.py'")
    exit()

# ==================== 1. é…ç½®ä¸Žè¾…åŠ©å‡½æ•° ====================

class ModelConfig:
    """æ¨¡åž‹é…ç½®ç±» - ä½¿ç”¨æ­£ç¡®çš„èŠ‚ç‚¹åˆ†ç»„"""
    def __init__(self, mix_ratio, d_model=92):
        self.mix_ratio = mix_ratio
        self.d_model = d_model
        self.device = torch.device('cpu')
        
        # æ¨¡åž‹å‚æ•°
        self.n_layer = 1
        self.n_head = 1
        self.n_embd = d_model
        self.vocab_size = 92
        
        # æ•°æ®ç›®å½•
        self.data_dir = 'data/simple_graph/standardized_alpine_90_seed42'
        
        # åŠ è½½æ­£ç¡®çš„èŠ‚ç‚¹åˆ†ç»„å’Œå›¾ç»“æž„
        self.load_stage_info()
        self.load_graph_structure()
    
    def load_stage_info(self):
        """åŠ è½½æ­£ç¡®çš„èŠ‚ç‚¹åˆ†ç»„ä¿¡æ¯"""
        stage_info_path = os.path.join(self.data_dir, 'stage_info.pkl')
        
        if not os.path.exists(stage_info_path):
            raise FileNotFoundError(f"stage_info.pkl not found at {stage_info_path}")
        
        with open(stage_info_path, 'rb') as f:
            stage_info = pickle.load(f)
        
        self.S1, self.S2, self.S3 = stage_info['stages']
        
        # è½¬æ¢ä¸ºé›†åˆä»¥ä¾¿å¿«é€ŸæŸ¥æ‰¾
        self.S1_set = set(self.S1)
        self.S2_set = set(self.S2)
        self.S3_set = set(self.S3)
        
        # åˆ›å»ºèŠ‚ç‚¹åˆ°tokençš„æ˜ å°„ï¼ˆ+2æ˜¯å› ä¸ºtoken 0,1æ˜¯ç‰¹æ®Štokenï¼‰
        self.node_to_token = {node: node + 2 for node in range(90)}
        self.token_to_node = {token: node for node, token in self.node_to_token.items()}
        
        # åˆ›å»ºS1, S2, S3çš„tokenç´¢å¼•
        self.S1_tokens = [self.node_to_token[n] for n in self.S1]
        self.S2_tokens = [self.node_to_token[n] for n in self.S2]
        self.S3_tokens = [self.node_to_token[n] for n in self.S3]
        
        print(f"  âœ“ Loaded stage info:")
        print(f"    S1: {len(self.S1)} nodes - {sorted(self.S1)[:10]}...")
        print(f"    S2: {len(self.S2)} nodes - {sorted(self.S2)[:10]}...")
        print(f"    S3: {len(self.S3)} nodes - {sorted(self.S3)[:10]}...")
    
    def load_graph_structure(self):
        """åŠ è½½å›¾ç»“æž„æ–‡ä»¶"""
        graph_path = os.path.join(self.data_dir, 'composition_graph.graphml')
        
        if not os.path.exists(graph_path):
            raise FileNotFoundError(f"Graph file not found at {graph_path}")
        
        print(f"  Loading graph from: {graph_path}")
        G = nx.read_graphml(graph_path)
        self.G = nx.relabel_nodes(G, {node: int(node) for node in G.nodes()})
        
        print(f"  âœ“ Graph loaded: {self.G.number_of_nodes()} nodes, {self.G.number_of_edges()} edges")
        
        # åˆ›å»º92x92çš„é‚»æŽ¥çŸ©é˜µï¼ˆåŒ…å«ç‰¹æ®Štokenï¼‰
        self.A_true = np.zeros((self.vocab_size, self.vocab_size))
        
        # å¡«å……é‚»æŽ¥çŸ©é˜µï¼ˆè€ƒè™‘tokenåç§»ï¼‰
        for edge in self.G.edges():
            source_token = self.node_to_token[edge[0]]
            target_token = self.node_to_token[edge[1]]
            self.A_true[source_token, target_token] = 1
        
        # ç»Ÿè®¡å„ç±»åž‹è¾¹çš„æ•°é‡
        self.count_edges()
    
    def count_edges(self):
        """ç»Ÿè®¡å„ç±»åž‹è¾¹çš„æ•°é‡"""
        s1_s2_edges = 0
        s2_s3_edges = 0
        s1_s3_edges = 0
        
        for edge in self.G.edges():
            source, target = edge[0], edge[1]
            if source in self.S1_set and target in self.S2_set:
                s1_s2_edges += 1
            elif source in self.S2_set and target in self.S3_set:
                s2_s3_edges += 1
            elif source in self.S1_set and target in self.S3_set:
                s1_s3_edges += 1
        
        print(f"  Edge statistics:")
        print(f"    S1->S2 edges: {s1_s2_edges}")
        print(f"    S2->S3 edges: {s2_s3_edges}")
        print(f"    S1->S3 edges: {s1_s3_edges}")
        
        self.edge_stats = {
            'S1->S2': s1_s2_edges,
            'S2->S3': s2_s3_edges,
            'S1->S3': s1_s3_edges
        }

def find_checkpoint(mix_ratio, d_model, iteration):
    """æŸ¥æ‰¾checkpointæ–‡ä»¶"""
    if mix_ratio == 0:
        patterns = [
            f"out/composition_d{d_model}_0mix_*/ckpt_{iteration}.pt",
            f"out_d{d_model}/composition_mix0_*/ckpt_*{iteration}.pt",
        ]
    else:
        patterns = [
            f"out/composition_d{d_model}_{mix_ratio}mix_*/ckpt_{iteration}.pt",
            f"out_d{d_model}/composition_mix{mix_ratio}_*/ckpt_*{iteration}.pt",
        ]
    
    for pattern in patterns:
        files = glob.glob(pattern)
        if files:
            return files[0]
    return None

def extract_W_M_prime(checkpoint_path, config):
    """æå–W'_MçŸ©é˜µ"""
    try:
        checkpoint = torch.load(checkpoint_path, map_location=config.device, weights_only=False)
        
        model_args = checkpoint.get('model_args', {})
        if not model_args:
            model_args = {
                'n_layer': config.n_layer,
                'n_head': config.n_head,
                'n_embd': config.n_embd,
                'vocab_size': config.vocab_size,
                'block_size': 512,
                'dropout': 0.0,
                'bias': False
            }
        
        model_args['vocab_size'] = config.vocab_size
        
        gptconf = GPTConfig(**model_args)
        model = GPT(gptconf).to(config.device)
        model.load_state_dict(checkpoint['model'], strict=False)
        model.eval()
        
        W_M_prime = []
        with torch.no_grad():
            for i in range(config.vocab_size):
                token_emb = model.transformer.wte(torch.tensor([i], device=config.device))
                ffn_out = model.transformer.h[0].mlp(token_emb)
                combined = token_emb + ffn_out
                logits = model.lm_head(combined)
                W_M_prime.append(logits.squeeze().cpu().numpy()[:config.vocab_size])
        
        return np.array(W_M_prime)
        
    except Exception as e:
        print(f"    Error extracting W_M_prime: {e}")
        raise

def calculate_path_statistics_correct(W_M_prime, config, path_type):
    """è®¡ç®—è·¯å¾„ç»Ÿè®¡ - ä½¿ç”¨æ­£ç¡®çš„èŠ‚ç‚¹åˆ†ç»„"""
    if path_type == 'S1->S2':
        source_tokens = config.S1_tokens
        target_tokens = config.S2_tokens
    elif path_type == 'S2->S3':
        source_tokens = config.S2_tokens
        target_tokens = config.S3_tokens
    elif path_type == 'S1->S3':
        source_tokens = config.S1_tokens
        target_tokens = config.S3_tokens
    else:
        raise ValueError(f"Invalid path_type: {path_type}")
    
    # æå–ç›¸å…³çš„å­çŸ©é˜µ
    W_sub = W_M_prime[np.ix_(source_tokens, target_tokens)]
    A_sub = config.A_true[np.ix_(source_tokens, target_tokens)]
    
    # åˆ›å»ºæŽ©ç 
    edge_mask = (A_sub == 1)
    non_edge_mask = (A_sub == 0)
    
    stats = {
        'num_edges': np.sum(edge_mask),
        'num_non_edges': np.sum(non_edge_mask)
    }
    
    if stats['num_edges'] > 0:
        stats['avg_edge_weight'] = np.mean(W_sub[edge_mask])
        stats['std_edge_weight'] = np.std(W_sub[edge_mask])
    else:
        stats['avg_edge_weight'] = np.nan
        stats['std_edge_weight'] = np.nan
    
    if stats['num_non_edges'] > 0:
        stats['avg_non_edge_weight'] = np.mean(W_sub[non_edge_mask])
        stats['std_non_edge_weight'] = np.std(W_sub[non_edge_mask])
    else:
        stats['avg_non_edge_weight'] = 0
        stats['std_non_edge_weight'] = 0
    
    if stats['num_edges'] > 0:
        stats['gap'] = stats['avg_edge_weight'] - stats['avg_non_edge_weight']
    else:
        stats['gap'] = np.nan
    
    return stats

# ==================== 2. æ•°æ®æ”¶é›†å‡½æ•° ====================

def collect_evolution_data(config, iterations):
    """æ”¶é›†å•ä¸ªæ¨¡åž‹çš„æ¼”åŒ–æ•°æ®"""
    model_name = f"{config.mix_ratio}% mix"
    print(f"\nðŸ“Š Processing {model_name} model...")
    
    model_data = {
        'S1->S2': {'edge': [], 'non_edge': [], 'gap': []},
        'S2->S3': {'edge': [], 'non_edge': [], 'gap': []},
        'S1->S3': {'edge': [], 'non_edge': [], 'gap': []}
    }
    
    found_checkpoints = 0
    for iteration in tqdm(iterations, desc=f"Loading checkpoints"):
        checkpoint_path = find_checkpoint(config.mix_ratio, config.d_model, iteration)
        
        if checkpoint_path is None:
            for path_type in model_data.keys():
                model_data[path_type]['edge'].append(np.nan)
                model_data[path_type]['non_edge'].append(np.nan)
                model_data[path_type]['gap'].append(np.nan)
            continue
        
        try:
            W_M_prime = extract_W_M_prime(checkpoint_path, config)
            found_checkpoints += 1
            
            for path_type in ['S1->S2', 'S2->S3', 'S1->S3']:
                stats = calculate_path_statistics_correct(W_M_prime, config, path_type)
                model_data[path_type]['edge'].append(stats['avg_edge_weight'])
                model_data[path_type]['non_edge'].append(stats['avg_non_edge_weight'])
                model_data[path_type]['gap'].append(stats['gap'])
                
        except Exception as e:
            print(f"  âš ï¸ Error at iteration {iteration}: {e}")
            for path_type in model_data.keys():
                model_data[path_type]['edge'].append(np.nan)
                model_data[path_type]['non_edge'].append(np.nan)
                model_data[path_type]['gap'].append(np.nan)
    
    print(f"  âœ“ Found {found_checkpoints}/{len(iterations)} checkpoints")
    return model_data

# ==================== 3. å¯è§†åŒ–å‡½æ•° ====================

def plot_complete_analysis(data_0mix, data_20mix, iterations, save_dir):
    """ç”Ÿæˆå®Œæ•´çš„å¯¹æ¯”åˆ†æžå›¾ - åŒ…å«æ‰€æœ‰ä¸‰ç§è·¯å¾„"""
    fig, axes = plt.subplots(3, 3, figsize=(18, 14))
    fig.suptitle('Weight Gap Evolution: 0% vs 20% Mix Models (Complete Analysis)', fontsize=16, fontweight='bold')
    
    path_types = ['S1->S2', 'S2->S3', 'S1->S3']
    colors = {'0% mix': 'blue', '20% mix': 'red'}
    
    for i, path_type in enumerate(path_types):
        # ç¬¬1åˆ—ï¼šEdgeæƒé‡ (å¯¹S1->S3æ˜¾ç¤ºnon-edgeæƒé‡)
        ax = axes[i, 0]
        
        if path_type != 'S1->S3':
            # æ­£å¸¸çš„edgeæƒé‡
            for model_name, data in [('0% mix', data_0mix), ('20% mix', data_20mix)]:
                edge_weights = data[path_type]['edge']
                valid_iters = [it for it, w in zip(iterations, edge_weights) if not np.isnan(w)]
                valid_weights = [w for w in edge_weights if not np.isnan(w)]
                
                if valid_weights:
                    ax.plot(valid_iters, valid_weights, marker='o', label=model_name,
                           color=colors[model_name], linewidth=2, markersize=5, alpha=0.8)
            
            ax.set_title('Average Edge Weight' if i == 0 else '', fontsize=13)
        else:
            # S1->S3: æ˜¾ç¤ºæ‰€æœ‰æƒé‡çš„å¹³å‡å€¼
            for model_name, data in [('0% mix', data_0mix), ('20% mix', data_20mix)]:
                non_edge_weights = data[path_type]['non_edge']
                valid_iters = [it for it, w in zip(iterations, non_edge_weights) if not np.isnan(w)]
                valid_weights = [w for w in non_edge_weights if not np.isnan(w)]
                
                if valid_weights:
                    ax.plot(valid_iters, valid_weights, marker='o', label=model_name,
                           color=colors[model_name], linewidth=2, markersize=5, alpha=0.8)
            
            ax.set_title('Avg Weight (No true edges)' if i == 0 else '', fontsize=13)
            ax.text(0.5, 0.95, 'No S1â†’S3 edges in data',
                   transform=ax.transAxes, ha='center', va='top',
                   fontsize=10, color='gray', style='italic')
        
        ax.set_ylabel(f'{path_type}', fontsize=12, fontweight='bold')
        ax.grid(True, alpha=0.3)
        ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5)
        if i == 0:
            ax.legend(loc='best')
        
        # ç¬¬2åˆ—ï¼šNon-edgeæƒé‡
        ax = axes[i, 1]
        
        for model_name, data in [('0% mix', data_0mix), ('20% mix', data_20mix)]:
            non_edge_weights = data[path_type]['non_edge']
            valid_iters = [it for it, w in zip(iterations, non_edge_weights) if not np.isnan(w)]
            valid_weights = [w for w in non_edge_weights if not np.isnan(w)]
            
            if valid_weights:
                ax.plot(valid_iters, valid_weights, marker='s', label=model_name,
                       color=colors[model_name], linewidth=2, markersize=5, 
                       alpha=0.8, linestyle='--')
        
        ax.set_title('Average Non-Edge Weight' if i == 0 else '', fontsize=13)
        ax.grid(True, alpha=0.3)
        ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5)
        if i == 0:
            ax.legend(loc='best')
        
        # ç¬¬3åˆ—ï¼šWeight Gap (å¯¹S1->S3æ˜¾ç¤ºæƒé‡åˆ†æž)
        ax = axes[i, 2]
        
        if path_type != 'S1->S3':
            # æ­£å¸¸çš„gap
            for model_name, data in [('0% mix', data_0mix), ('20% mix', data_20mix)]:
                gaps = data[path_type]['gap']
                valid_iters = [it for it, g in zip(iterations, gaps) if not np.isnan(g)]
                valid_gaps = [g for g in gaps if not np.isnan(g)]
                
                if valid_gaps:
                    ax.plot(valid_iters, valid_gaps, marker='^', label=model_name,
                           color=colors[model_name], linewidth=2.5, markersize=7)
                    
                    # æ ‡æ³¨æœ€ç»ˆå€¼
                    final_gap = valid_gaps[-1]
                    ax.annotate(f'{final_gap:.3f}', 
                              xy=(valid_iters[-1], final_gap),
                              xytext=(5, 5), textcoords='offset points',
                              fontsize=8, color=colors[model_name])
                    
                    # S2->S3ç‰¹æ®Šæ ‡æ³¨
                    if path_type == 'S2->S3' and min(valid_gaps) > 0:
                        ax.text(0.95, 0.05, 'âœ… S2 preserved', 
                               transform=ax.transAxes, ha='right', va='bottom',
                               bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.5))
            
            ax.set_title('Weight Gap (Edge - Non-Edge)' if i == 0 else '', fontsize=13)
        else:
            # S1->S3: æƒé‡åˆ†æž
            ax.text(0.5, 0.5, 'No direct edges\nto compute gap', 
                   transform=ax.transAxes, ha='center', va='center',
                   fontsize=12, color='gray', style='italic')
            ax.set_title('Gap N/A (No edges)' if i == 0 else '', fontsize=13)
        
        ax.grid(True, alpha=0.3)
        if i == 0 and path_type != 'S1->S3':
            ax.legend(loc='best')
    
    # è®¾ç½®xè½´
    for i in range(3):
        for j in range(3):
            axes[i, j].set_xlabel('Training Iterations', fontsize=11)
            axes[i, j].set_xticks(iterations[::2])
            axes[i, j].set_xticklabels([f'{k//1000}k' for k in iterations[::2]], rotation=45)
    
    plt.tight_layout(rect=[0, 0, 1, 0.96])
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    save_path = os.path.join(save_dir, f'weight_gap_complete_comparison_{timestamp}.png')
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"âœ… Complete analysis plot saved to: {save_path}")
    plt.show()

# ==================== 4. ä¸»å‡½æ•° ====================

def main():
    """ä¸»å‡½æ•° - å®Œæ•´åˆ†æž"""
    print("\n" + "="*80)
    print("ðŸ”¬ COMPLETE WEIGHT GAP ANALYSIS WITH ALL PATHS")
    print("="*80)
    
    d_model = 92
    iterations = list(range(5000, 51000, 5000))
    save_dir = 'weight_gap_analysis_complete'
    os.makedirs(save_dir, exist_ok=True)
    
    # æ”¶é›†ä¸¤ä¸ªæ¨¡åž‹çš„æ•°æ®
    all_data = {}
    
    for mix_ratio in [0, 20]:
        print(f"\n{'='*60}")
        print(f"Analyzing {mix_ratio}% mix model")
        print('='*60)
        
        config = ModelConfig(mix_ratio=mix_ratio, d_model=d_model)
        evolution_data = collect_evolution_data(config, iterations)
        all_data[f'{mix_ratio}% mix'] = evolution_data
        
        # æ‰“å°è¯¦ç»†ç»Ÿè®¡
        print(f"\nðŸ“Š Detailed Statistics for {mix_ratio}% mix model:")
        print("-" * 50)
        
        for path_type in ['S1->S2', 'S2->S3', 'S1->S3']:
            print(f"\n{path_type}:")
            
            if path_type != 'S1->S3':
                # æ­£å¸¸è·¯å¾„åˆ†æž
                gaps = evolution_data[path_type]['gap']
                valid_gaps = [g for g in gaps if not np.isnan(g)]
                
                if valid_gaps:
                    print(f"  Gap statistics:")
                    print(f"    Initial: {valid_gaps[0]:.4f}")
                    print(f"    Final:   {valid_gaps[-1]:.4f}")
                    print(f"    Min:     {min(valid_gaps):.4f}")
                    print(f"    Max:     {max(valid_gaps):.4f}")
                    
                    if path_type == 'S2->S3':
                        if min(valid_gaps) > 0:
                            print(f"    âœ… Always positive - S2 preserved!")
                        else:
                            print(f"    âš ï¸ Goes negative - S2 may be suppressed")
            else:
                # S1->S3åˆ†æžï¼ˆæ— çœŸå®žè¾¹ï¼‰
                non_edge_weights = evolution_data[path_type]['non_edge']
                valid_weights = [w for w in non_edge_weights if not np.isnan(w)]
                
                if valid_weights:
                    print(f"  Weight statistics (no true edges in data):")
                    print(f"    Initial: {valid_weights[0]:.4f}")
                    print(f"    Final:   {valid_weights[-1]:.4f}")
                    print(f"    Min:     {min(valid_weights):.4f}")
                    print(f"    Max:     {max(valid_weights):.4f}")
                    
                    # æ£€æŸ¥æ˜¯å¦å­¦ä¹ äº†è™šå‡è¿žæŽ¥
                    threshold = 0.1
                    if max(np.abs(valid_weights)) > threshold:
                        print(f"    âš ï¸ Model assigns weight > {threshold} to non-existent paths!")
                    else:
                        print(f"    âœ… Weights remain small (< {threshold})")
    
    # ç”Ÿæˆå®Œæ•´å¯¹æ¯”å›¾
    print("\n" + "="*80)
    print("ðŸ“Š GENERATING COMPLETE COMPARISON PLOT")
    print("="*80)
    
    plot_complete_analysis(
        all_data['0% mix'], 
        all_data['20% mix'], 
        iterations, 
        save_dir
    )
    
    print("\n" + "="*80)
    print("âœ… COMPLETE ANALYSIS FINISHED!")
    print("="*80)

if __name__ == "__main__":
    main()