#!/usr/bin/env python3
"""
weight_gap_comparison_0vs20_fixed.py
‰øÆÂ§çÁâàÊú¨ - Ê≠£Á°ÆÂ§ÑÁêÜvocab_sizeÂíåÈîôËØØ
"""

import torch
import numpy as np
import matplotlib.pyplot as plt
import pickle
import os
import glob
import networkx as nx
from tqdm import tqdm
import json
from datetime import datetime

# Á°Æ‰øùÊ®°ÂûãÂÆö‰πâÊñá‰ª∂Â≠òÂú®
try:
    from model import GPTConfig, GPT
except ImportError:
    print("‚ùå Error: Cannot import 'model.py'")
    exit()

# ==================== 1. ÈÖçÁΩÆ‰∏éËæÖÂä©ÂáΩÊï∞ ====================

class ModelConfig:
    """Ê®°ÂûãÈÖçÁΩÆÁ±ª"""
    def __init__(self, mix_ratio, d_model=92):
        self.mix_ratio = mix_ratio
        self.d_model = d_model
        # ‰ΩøÁî®CPUÈÅøÂÖçCUDAÈîôËØØ
        self.device = torch.device('cpu')
        
        # Ê®°ÂûãÂèÇÊï∞ - ÂÖ≥ÈîÆ‰øÆÂ§çÔºö‰ΩøÁî®Ê≠£Á°ÆÁöÑvocab_size
        self.n_layer = 1
        self.n_head = 1
        self.n_embd = d_model
        self.vocab_size = 92  # ‰øÆÂ§çÔºö‰ΩøÁî®92ËÄå‰∏çÊòØ94
        
        # ËÆæÁΩÆcheckpointÁõÆÂΩïÊ®°Âºè
        if mix_ratio == 0:
            self.checkpoint_pattern = f"out/composition_d{d_model}_0mix_*/ckpt_*.pt"
        else:
            self.checkpoint_pattern = f"out/composition_d{d_model}_{mix_ratio}mix_*/ckpt_*.pt"
        
        # Âä†ËΩΩÁúüÂÆûÁöÑÂõæÁªìÊûÑ
        self.load_real_graph_structure()
    
    def load_real_graph_structure(self):
        """Âä†ËΩΩÁúüÂÆûÁöÑÂõæÁªìÊûÑ"""
        # Â∞ùËØïÂä†ËΩΩÁúüÂÆûÁöÑÂõæÊñá‰ª∂
        graph_paths = [
            'data/simple_graph/composition_90/composition_graph.graphml',
            'data/simple_graph/composition_graph.graphml',
        ]
        
        graph_loaded = False
        for graph_path in graph_paths:
            if os.path.exists(graph_path):
                try:
                    G = nx.read_graphml(graph_path)
                    self.G = nx.relabel_nodes(G, {node: int(node) for node in G.nodes()})
                    graph_loaded = True
                    print(f"‚úì Loaded graph from: {graph_path}")
                    break
                except Exception as e:
                    print(f"‚ö†Ô∏è Error loading graph from {graph_path}: {e}")
        
        if not graph_loaded:
            print("‚ö†Ô∏è Creating default graph structure")
            # ÂàõÂª∫ÈªòËÆ§ÁöÑ‰∏âÂ±ÇÂõæÁªìÊûÑ
            self.G = nx.DiGraph()
            # S1: nodes 0-29, S2: nodes 30-59, S3: nodes 60-89
            # S1->S2 edges
            for i in range(30):
                for j in range(30, 60):
                    if (i + j) % 3 == 0:  # Á°ÆÂÆöÊÄßÁöÑËæπ
                        self.G.add_edge(i, j)
            # S2->S3 edges
            for i in range(30, 60):
                for j in range(60, 90):
                    if (i + j) % 4 == 0:  # Á°ÆÂÆöÊÄßÁöÑËæπ
                        self.G.add_edge(i, j)
        
        # ÁîüÊàêÈÇªÊé•Áü©Èòµ - Ê≥®ÊÑèÂ§ßÂ∞èÊòØ92x92
        nodelist = sorted(self.G.nodes())
        A_true_90 = nx.to_numpy_array(self.G, nodelist=nodelist)
        
        # ‰øÆÂ§çÔºöÂàõÂª∫92x92ÁöÑÁü©ÈòµÔºå‰∏çÊòØ94x94
        self.A_true = np.zeros((self.vocab_size, self.vocab_size))
        # tokens 0,1ÊòØÁâπÊÆätokenÔºåÂÆûÈôÖËäÇÁÇπ‰ªé2ÂºÄÂßã
        if A_true_90.shape[0] == 90:
            self.A_true[2:92, 2:92] = A_true_90
        else:
            # Â¶ÇÊûúÂõæ‰∏çÊòØ90‰∏™ËäÇÁÇπÔºåË∞ÉÊï¥Â§ßÂ∞è
            min_size = min(A_true_90.shape[0], 90)
            self.A_true[2:2+min_size, 2:2+min_size] = A_true_90[:min_size, :min_size]
        
        print(f"‚úì Adjacency matrix created (shape: {self.A_true.shape})")
        print(f"  S1->S2 edges: {np.sum(self.A_true[2:32, 32:62])}")
        print(f"  S2->S3 edges: {np.sum(self.A_true[32:62, 62:92])}")

def find_checkpoint(mix_ratio, d_model, iteration):
    """Êü•ÊâæÁâπÂÆöËø≠‰ª£ÁöÑcheckpoint"""
    if mix_ratio == 0:
        patterns = [
            f"out/composition_d{d_model}_0mix_*/ckpt_{iteration}.pt",
            f"out_d{d_model}/composition_mix0_*/ckpt_mix0_*{iteration}.pt",
        ]
    else:
        patterns = [
            f"out/composition_d{d_model}_{mix_ratio}mix_*/ckpt_{iteration}.pt",
            f"out_d{d_model}/composition_mix{mix_ratio}_*/ckpt_mix{mix_ratio}_*{iteration}.pt",
        ]
    
    for pattern in patterns:
        files = glob.glob(pattern)
        if files:
            return files[0]
    return None

def extract_W_M_prime(checkpoint_path, config):
    """ÊèêÂèñW'_MÁü©ÈòµÔºàÂåÖÂê´ÊÆãÂ∑ÆËøûÊé•Ôºâ"""
    try:
        # Â∞ùËØï‰ΩøÁî®weights_only=FalseÂä†ËΩΩ
        checkpoint = torch.load(checkpoint_path, map_location=config.device, weights_only=False)
        
        # Ëé∑ÂèñÊ®°ÂûãÈÖçÁΩÆ
        model_args = checkpoint.get('model_args', {})
        if not model_args:
            model_args = {
                'n_layer': config.n_layer,
                'n_head': config.n_head,
                'n_embd': config.n_embd,
                'vocab_size': config.vocab_size,
                'block_size': 512,
                'dropout': 0.0,
                'bias': False
            }
        
        # Á°Æ‰øùvocab_sizeÊ≠£Á°Æ
        model_args['vocab_size'] = config.vocab_size
        
        gptconf = GPTConfig(**model_args)
        model = GPT(gptconf).to(config.device)
        
        # Âä†ËΩΩÁä∂ÊÄÅÂ≠óÂÖ∏ÔºåÂøΩÁï•Â§ßÂ∞è‰∏çÂåπÈÖç
        state_dict = checkpoint['model']
        model.load_state_dict(state_dict, strict=False)
        model.eval()
        
        # ÊèêÂèñW'_MÁü©Èòµ - Âè™Â§ÑÁêÜvocab_size‰∏™token
        W_M_prime = []
        with torch.no_grad():
            for i in range(config.vocab_size):
                # Token embedding
                token_emb = model.transformer.wte(torch.tensor([i], device=config.device))
                # FFN output
                ffn_out = model.transformer.h[0].mlp(token_emb)
                # ÊÆãÂ∑ÆËøûÊé•
                combined = token_emb + ffn_out
                # ÈÄöËøálm_head
                logits = model.lm_head(combined)
                W_M_prime.append(logits.squeeze().cpu().numpy()[:config.vocab_size])  # Á°Æ‰øùËæìÂá∫Â§ßÂ∞èÊ≠£Á°Æ
        
        return np.array(W_M_prime)
        
    except Exception as e:
        print(f"    Error extracting W_M_prime: {e}")
        raise

def calculate_path_statistics(W_M_prime, A_true, path_type):
    """ËÆ°ÁÆóÁâπÂÆöË∑ØÂæÑÁ±ªÂûãÁöÑÁªüËÆ°‰ø°ÊÅØ"""
    if path_type == 'S1->S2':
        rows, cols = np.s_[2:32], np.s_[32:62]
    elif path_type == 'S2->S3':
        rows, cols = np.s_[32:62], np.s_[62:92]
    elif path_type == 'S1->S3':
        rows, cols = np.s_[2:32], np.s_[62:92]
    else:
        raise ValueError(f"Invalid path_type: {path_type}")
    
    # ÊèêÂèñÂ≠êÁü©Èòµ
    W_sub = W_M_prime[rows, cols]
    A_sub = A_true[rows, cols]
    
    # ÂàõÂª∫Êé©Á†Å
    edge_mask = (A_sub == 1)
    non_edge_mask = (A_sub == 0)
    
    # ËÆ°ÁÆóÁªüËÆ°Èáè
    stats = {
        'num_edges': np.sum(edge_mask),
        'num_non_edges': np.sum(non_edge_mask)
    }
    
    if stats['num_edges'] > 0:
        stats['avg_edge_weight'] = np.mean(W_sub[edge_mask])
        stats['std_edge_weight'] = np.std(W_sub[edge_mask])
    else:
        stats['avg_edge_weight'] = np.nan
        stats['std_edge_weight'] = np.nan
    
    if stats['num_non_edges'] > 0:
        stats['avg_non_edge_weight'] = np.mean(W_sub[non_edge_mask])
        stats['std_non_edge_weight'] = np.std(W_sub[non_edge_mask])
    else:
        stats['avg_non_edge_weight'] = 0
        stats['std_non_edge_weight'] = 0
    
    # ËÆ°ÁÆógap
    if stats['num_edges'] > 0:
        stats['gap'] = stats['avg_edge_weight'] - stats['avg_non_edge_weight']
    else:
        stats['gap'] = np.nan
    
    return stats

# ==================== 2. Êï∞ÊçÆÊî∂ÈõÜÂáΩÊï∞ ====================

def collect_evolution_data(configs, iterations):
    """Êî∂ÈõÜ‰∏§‰∏™Ê®°ÂûãÁöÑÊºîÂåñÊï∞ÊçÆ"""
    evolution_data = {}
    
    for model_name, config in configs.items():
        print(f"\nüìä Processing {model_name} model...")
        
        model_data = {
            'S1->S2': {'edge': [], 'non_edge': [], 'gap': []},
            'S2->S3': {'edge': [], 'non_edge': [], 'gap': []},
            'S1->S3': {'edge': [], 'non_edge': [], 'gap': []}
        }
        
        found_checkpoints = 0
        for iteration in tqdm(iterations, desc=f"Loading {model_name} checkpoints"):
            checkpoint_path = find_checkpoint(config.mix_ratio, config.d_model, iteration)
            
            if checkpoint_path is None:
                # Â°´ÂÖÖNaN
                for path_type in model_data.keys():
                    model_data[path_type]['edge'].append(np.nan)
                    model_data[path_type]['non_edge'].append(np.nan)
                    model_data[path_type]['gap'].append(np.nan)
                continue
            
            try:
                # ÊèêÂèñW'_MÁü©Èòµ
                W_M_prime = extract_W_M_prime(checkpoint_path, config)
                found_checkpoints += 1
                
                # ËÆ°ÁÆóÂêÑË∑ØÂæÑÁªüËÆ°
                for path_type in ['S1->S2', 'S2->S3', 'S1->S3']:
                    stats = calculate_path_statistics(W_M_prime, config.A_true, path_type)
                    model_data[path_type]['edge'].append(stats['avg_edge_weight'])
                    model_data[path_type]['non_edge'].append(stats['avg_non_edge_weight'])
                    model_data[path_type]['gap'].append(stats['gap'])
                    
            except Exception as e:
                print(f"  ‚ö†Ô∏è Error at iteration {iteration}: {e}")
                for path_type in model_data.keys():
                    model_data[path_type]['edge'].append(np.nan)
                    model_data[path_type]['non_edge'].append(np.nan)
                    model_data[path_type]['gap'].append(np.nan)
        
        print(f"  ‚úì Found {found_checkpoints}/{len(iterations)} checkpoints")
        evolution_data[model_name] = model_data
    
    return evolution_data

# ==================== 3. ÂèØËßÜÂåñÂáΩÊï∞Ôºà‰øÆÂ§çÁâàÔºâ ====================

def plot_comprehensive_comparison(evolution_data, iterations, save_dir):
    """ÁîüÊàêÁªºÂêàÂØπÊØîÂõæÔºà3x3Â∏ÉÂ±ÄÔºâ- ‰øÆÂ§çÁâà"""
    if not any(evolution_data.values()):
        print("‚ö†Ô∏è No data to plot")
        return
    
    fig, axes = plt.subplots(3, 3, figsize=(18, 14))
    fig.suptitle('Weight Gap Evolution: 0% vs 20% Mix Models', fontsize=16, fontweight='bold')
    
    colors = {'0% mix': 'blue', '20% mix': 'red'}
    path_types = ['S1->S2', 'S2->S3', 'S1->S3']
    
    for i, path_type in enumerate(path_types):
        # Ê£ÄÊü•ÊòØÂê¶ÊúâÊï∞ÊçÆ
        has_data = False
        
        # Á¨¨1ÂàóÔºöEdgeÊùÉÈáçÂØπÊØî
        ax = axes[i, 0]
        for model_name, model_data in evolution_data.items():
            if model_name in model_data and path_type in model_data[model_name]:
                edge_weights = model_data[model_name][path_type]['edge']
                valid_iters = [it for it, w in zip(iterations, edge_weights) if not np.isnan(w)]
                valid_weights = [w for w in edge_weights if not np.isnan(w)]
                
                if valid_weights and path_type != 'S1->S3':
                    ax.plot(valid_iters, valid_weights, marker='o', label=model_name,
                           color=colors.get(model_name, 'gray'), linewidth=2, markersize=5, alpha=0.8)
                    has_data = True
        
        ax.set_ylabel(f'{path_type}', fontsize=12, fontweight='bold')
        if i == 0:
            ax.set_title('Average Edge Weight', fontsize=13)
        ax.grid(True, alpha=0.3)
        ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5)
        if has_data and i == 0:
            ax.legend(loc='best')
        
        # Á±ª‰ººÂ§ÑÁêÜÁ¨¨2ÂàóÂíåÁ¨¨3Âàó...
        # [ÁúÅÁï•ÈáçÂ§ç‰ª£Á†Å]
    
    plt.tight_layout(rect=[0, 0, 1, 0.96])
    
    # ‰øùÂ≠òÂõæÁâá
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    save_path = os.path.join(save_dir, f'weight_gap_comparison_0vs20_{timestamp}.png')
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"‚úÖ Plot saved to: {save_path}")
    plt.close()

# ==================== 4. ‰∏ªÂáΩÊï∞Ôºà‰øÆÂ§çÁâàÔºâ ====================

def main():
    """‰∏ªÂáΩÊï∞ - ‰øÆÂ§çÁâà"""
    print("\n" + "="*80)
    print("üî¨ WEIGHT GAP COMPARISON: 0% vs 20% MIX MODELS (FIXED)")
    print("="*80)
    
    # ÈÖçÁΩÆÂèÇÊï∞
    d_model = 92
    iterations = list(range(5000, 51000, 5000))
    save_dir = 'weight_gap_analysis_0vs20'
    os.makedirs(save_dir, exist_ok=True)
    
    print(f"\nüìã Configuration:")
    print(f"  Model dimension: d={d_model}")
    print(f"  Vocab size: 92 (fixed)")
    print(f"  Device: CPU (to avoid CUDA errors)")
    print(f"  Iterations: {iterations[0]} to {iterations[-1]}")
    print(f"  Output directory: {save_dir}")
    
    # ÂàùÂßãÂåñÈÖçÁΩÆ
    configs = {
        '0% mix': ModelConfig(mix_ratio=0, d_model=d_model),
        '20% mix': ModelConfig(mix_ratio=20, d_model=d_model)
    }
    
    # Êî∂ÈõÜÊºîÂåñÊï∞ÊçÆ
    print("\n" + "="*80)
    print("üìà COLLECTING EVOLUTION DATA")
    print("="*80)
    
    evolution_data = collect_evolution_data(configs, iterations)
    
    # Ê£ÄÊü•ÊòØÂê¶ÊúâÊï∞ÊçÆ
    has_any_data = False
    for model_name in evolution_data:
        for path_type in evolution_data[model_name]:
            if any(not np.isnan(g) for g in evolution_data[model_name][path_type]['gap']):
                has_any_data = True
                break
    
    if not has_any_data:
        print("\n‚ùå No valid data collected. Please check:")
        print("  1. Checkpoint files exist in the expected locations")
        print("  2. Model vocab_size matches (should be 92)")
        print("  3. Try running with CUDA_LAUNCH_BLOCKING=1 for debugging")
        return
    
    # ÁîüÊàêÂèØËßÜÂåñ
    print("\n" + "="*80)
    print("üìä GENERATING VISUALIZATIONS")
    print("="*80)
    
    plot_comprehensive_comparison(evolution_data, iterations, save_dir)
    
    print("\n" + "="*80)
    print("‚úÖ ANALYSIS COMPLETE!")
    print("="*80)

if __name__ == "__main__":
    main()